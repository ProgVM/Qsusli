import telebot
import json
import os
import threading
import time
import logging
import torch
import random
import traceback
from qsusli_model import GlobalWorkspace, load_model, generate_text, tokens_to_indices, split_text_to_sentences, fine_tune, search_wikipedia, generate_image_from_text, process_rlhf_correction
from db import DB

db = DB()

API_TOKEN = '8034310036:AAFLGX0lEtnOdFAj7OSurkNz7e3dVCorE2U'

bot = telebot.TeleBot(API_TOKEN)

model_path = 'qsusli_model.pth'

workspaces = {}
activity_settings = {}
user_last_outputs = {}
user_training_buffers = {}

if os.path.exists(model_path):
    print("–ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏...")
    model, optimizer, bpe = load_model(model_path)
else:
    print("–§–∞–π–ª –º–æ–¥–µ–ª–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω. –û–±—É—á–µ–Ω–∏–µ –Ω–æ–≤–æ–π –º–æ–¥–µ–ª–∏...")
    from qsusli_model import train_new_model
    model, optimizer, bpe = train_new_model()

inv_vocab = {v: k for k, v in bpe.vocab.items()}
is_finetuning = False
train_data_lock = threading.Lock()
fine_tune_threshold = 10

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(filename='bot.log', level=logging.INFO,
                    format='%(asctime)s %(levelname)s: %(message)s')

def load_activity_settings():
    global activity_settings
    raw_settings = db.load_all_group_settings()
    activity_settings.clear()
    for chat_id, settings in raw_settings.items():
        level_str = settings.get('activity_level')
        if level_str is not None:
            try:
                activity_settings[chat_id] = int(level_str)
            except ValueError:
                pass
    return activity_settings

load_activity_settings()

def save_activity_settings():
    for chat_id, level in activity_settings.items():
        db.set_group_setting(chat_id, 'activity_level', level)

# –ó–∞–≥—Ä—É–∂–∞–µ–º –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏ –ø—Ä–∏ —Å—Ç–∞—Ä—Ç–µ
load_activity_settings()

# –°–∏—Å—Ç–µ–º–∞ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è —á–∞—Å—Ç–æ—Ç—ã –∑–∞–ø—Ä–æ—Å–æ–≤
last_message_time = {}
message_count = {}
RATE_LIMIT_SECONDS = 1.5  # –ú–∏–Ω–∏–º–∞–ª—å–Ω–∞—è –∑–∞–¥–µ—Ä–∂–∫–∞ –º–µ–∂–¥—É —Å–æ–æ–±—â–µ–Ω–∏—è–º–∏
MAX_MESSAGES_PER_MINUTE = 20  # –ú–∞–∫—Å–∏–º—É–º —Å–æ–æ–±—â–µ–Ω–∏–π –≤ –º–∏–Ω—É—Ç—É

def can_send_message(chat_id):
    """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç –º–æ–∂–Ω–æ –ª–∏ –æ—Ç–ø—Ä–∞–≤–∏—Ç—å —Å–æ–æ–±—â–µ–Ω–∏–µ (rate limiting)"""
    current_time = time.time()
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø–æ—Å–ª–µ–¥–Ω–µ–µ –≤—Ä–µ–º—è –æ—Ç–ø—Ä–∞–≤–∫–∏
    if chat_id in last_message_time:
        time_diff = current_time - last_message_time[chat_id]
        if time_diff < RATE_LIMIT_SECONDS:
            return False
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–æ–æ–±—â–µ–Ω–∏–π –≤ –º–∏–Ω—É—Ç—É
    if chat_id in message_count:
        message_count[chat_id] = [(t, c) for t, c in message_count[chat_id] if current_time - t < 60]
        if len(message_count[chat_id]) >= MAX_MESSAGES_PER_MINUTE:
            return False
    else:
        message_count[chat_id] = []
    
    return True

def safe_send_message(message, text):
    """–ë–µ–∑–æ–ø–∞—Å–Ω–∞—è –æ—Ç–ø—Ä–∞–≤–∫–∞ —Å–æ–æ–±—â–µ–Ω–∏–π —Å –æ–±—Ä–∞–±–æ—Ç–∫–æ–π –æ—à–∏–±–æ–∫"""
    try:
        chat_id = message.chat.id
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ª–∏–º–∏—Ç—ã
        if not can_send_message(chat_id):
            logging.info(f"Rate limit: –ø—Ä–æ–ø—É—Å–∫ —Å–æ–æ–±—â–µ–Ω–∏—è –¥–ª—è —á–∞—Ç–∞ {chat_id}")
            return False
        
        # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º —Å–æ–æ–±—â–µ–Ω–∏–µ
        bot.reply_to(message, text)
        
        # –û–±–Ω–æ–≤–ª—è–µ–º —Å—á–µ—Ç—á–∏–∫–∏
        current_time = time.time()
        last_message_time[chat_id] = current_time
        if chat_id not in message_count:
            message_count[chat_id] = []
        message_count[chat_id].append((current_time, 1))
        
        return True
        
    except telebot.apihelper.ApiTelegramException as e:
        if e.error_code == 429:  # Too Many Requests
            retry_after = 60  # –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é 60 —Å–µ–∫—É–Ω–¥
            try:
                # –ü—ã—Ç–∞–µ–º—Å—è –∏–∑–≤–ª–µ—á—å –≤—Ä–µ–º—è –æ–∂–∏–¥–∞–Ω–∏—è –∏–∑ –æ–ø–∏—Å–∞–Ω–∏—è
                if "retry after" in e.description:
                    retry_after = int(e.description.split("retry after")[1].strip())
            except:
                pass
            
            logging.warning(f"Rate limit hit for chat {chat_id}, waiting {retry_after} seconds")
            time.sleep(min(retry_after, 120))  # –ú–∞–∫—Å–∏–º—É–º 2 –º–∏–Ω—É—Ç—ã –æ–∂–∏–¥–∞–Ω–∏—è
            return False
            
        else:
            logging.error(f"Telegram API error: {e}")
            return False
            
    except Exception as e:
        logging.error(f"Error sending message: {e}")
        return False

def load_train_data():
    return db.load_train_data()


def save_train_data(train_pairs):
    # train_pairs ‚Äî —Å–ø–∏—Å–æ–∫ –∫–æ—Ä—Ç–µ–∂–µ–π (input_text, output_text)
    for input_text, output_text in train_pairs:
        db.save_train_pair(input_text, output_text)


def clear_train_data():
    db.clear_train_data()


def auto_finetune_loop():
    global is_finetuning, model, optimizer, bpe
    while True:
        time.sleep(300)
        with train_data_lock:
            data = load_train_data()
            if len(data) >= fine_tune_threshold and not is_finetuning:
                logging.info("–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–π –∑–∞–ø—É—Å–∫ fine-tuning –ø–æ –Ω–∞–∫–æ–ø–ª–µ–Ω–∏—é –¥–∞–Ω–Ω—ã—Ö")
                is_finetuning = True
                try:
                    texts = [pair[0] for pair in data] + [pair[1] for pair in data]

                    sentences = []
                    for text in texts:
                        sentences.extend(split_text_to_sentences(text))
                    sentences = sentences[:50]

                    fine_tune(model, optimizer, bpe, sentences, epochs=10)

                    data.clear()
                    save_train_data(data)
                    logging.info("–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–π fine-tuning –∑–∞–≤–µ—Ä—à—ë–Ω")
                except Exception as e:
                    logging.error(f"–û—à–∏–±–∫–∞ –≤–æ –≤—Ä–µ–º—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–≥–æ fine-tuning: {e}")
                finally:
                    is_finetuning = False

@bot.message_handler(commands=['start', 'help'])
def send_welcome(message):
    welcome_text = (
        "–ü—Ä–∏–≤–µ—Ç! –Ø Qsusli ‚Äî —Ç–≤–æ–π AI-–∞—Å—Å–∏—Å—Ç–µ–Ω—Ç.\n\n"
        "–í–æ—Ç —á—Ç–æ —è —É–º–µ—é:\n"
        "üé® /image <–æ–ø–∏—Å–∞–Ω–∏–µ> ‚Äî —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å —Ä–µ–∞–ª–∏—Å—Ç–∏—á–Ω–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ\n"
        "üß† /brain <—Ç–µ–∫—Å—Ç> ‚Äî —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏–π –∞–Ω–∞–ª–∏–∑ —Ç–µ–∫—Å—Ç–∞\n"
        "‚≠ê /rate 1-5 ‚Äî –æ—Ü–µ–Ω–∏—Ç—å –ø–æ—Å–ª–µ–¥–Ω–µ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –∏–ª–∏ —Ç–µ–∫—Å—Ç–æ–≤–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ\n"
        "‚úçÔ∏è /correct <—Ç–µ–∫—Å—Ç> ‚Äî –ø—Ä–µ–¥–ª–æ–∂–∏—Ç—å –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–Ω—ã–π –æ—Ç–≤–µ—Ç –ò–ò –¥–ª—è –æ–±—É—á–µ–Ω–∏—è –∏ —É–ª—É—á—à–µ–Ω–∏—è\n"
        "üîß /finetune ‚Äî –¥–æ–æ–±—É—á–∏—Ç—å –º–æ–¥–µ–ª—å –Ω–∞ –Ω–∞–∫–æ–ø–ª–µ–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö\n"
        "üìä /activity 0-10 ‚Äî –Ω–∞—Å—Ç—Ä–æ–∏—Ç—å –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç—å –≤ –≥—Ä—É–ø–ø–∞—Ö\n\n"
        "üìù /train ‚Äî –Ω–∞—á–∞—Ç—å –≤–≤–æ–¥ —Ç–µ–∫—Å—Ç–∞ –¥–ª—è –¥–æ–æ–±—É—á–µ–Ω–∏—è (–º–Ω–æ–≥–æ—Å—Ç—Ä–æ—á–Ω—ã–π —Ç–µ–∫—Å—Ç –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç—Å—è):\n"
        "    –ü–æ—Å–ª–µ –∫–æ–º–∞–Ω–¥—ã –æ—Ç–ø—Ä–∞–≤–ª—è–π—Ç–µ —Ç–µ–∫—Å—Ç, –∫–æ–≥–¥–∞ –∑–∞–∫–æ–Ω—á–∏—Ç–µ ‚Äî –Ω–∞–ø–∏—à–∏—Ç–µ /done\n\n"
        "üßπ /clear ‚Äî –æ—á–∏—Å—Ç–∏—Ç—å —Ç–µ–∫—É—â–∏–π –∫–æ–Ω—Ç–µ–∫—Å—Ç –¥–∏–∞–ª–æ–≥–∞\n\n"
        "–ï—Å–ª–∏ –Ω—É–∂–Ω–∞ –ø–æ–º–æ—â—å, –ø–∏—à–∏ /help"
    )
    safe_send_message(message, welcome_text)
    logging.info(f"–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å {message.from_user.id} –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–ª /start")

@bot.message_handler(commands=['clear', 'reset', 'clearcontext', 'clear_context', 'resetcontext', 'reset_context'])
def clear_context(message):
    chat_id = message.chat.id
    workspace = workspaces.get(chat_id)
    if workspace:
        workspace.dialog_history.clear()
        workspace.context_keywords.clear()
        workspace.semantic_info = None
        workspace.current_prompt = None
        bot.reply_to(message, "–ö–æ–Ω—Ç–µ–∫—Å—Ç –æ—á–∏—â–µ–Ω.")
    else:
        bot.reply_to(message, "–ö–æ–Ω—Ç–µ–∫—Å—Ç –¥–ª—è —ç—Ç–æ–≥–æ —á–∞—Ç–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω.")

@bot.message_handler(commands=['activity'])
def set_activity(message):
    global activity_settings

    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –∫–æ–º–∞–Ω–¥–∞ –≤—ã–∑—ã–≤–∞–µ—Ç—Å—è –≤ –≥—Ä—É–ø–ø–µ –∏–ª–∏ —Å—É–ø–µ—Ä–≥—Ä—É–ø–ø–µ
    if message.chat.type not in ['group', 'supergroup']:
        bot.reply_to(message, "‚ùå –ö–æ–º–∞–Ω–¥–∞ /activity –¥–æ—Å—Ç—É–ø–Ω–∞ —Ç–æ–ª—å–∫–æ –≤ –≥—Ä—É–ø–ø–∞—Ö.")
        return

    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø—Ä–∞–≤–∞ –∞–¥–º–∏–Ω–∏—Å—Ç—Ä–∞—Ç–æ—Ä–∞
    try:
        member = bot.get_chat_member(message.chat.id, message.from_user.id)
        if member.status not in ['administrator', 'creator']:
            bot.reply_to(message, "‚ùå –¢–æ–ª—å–∫–æ –∞–¥–º–∏–Ω–∏—Å—Ç—Ä–∞—Ç–æ—Ä—ã –º–æ–≥—É—Ç –∏–∑–º–µ–Ω—è—Ç—å –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç—å –±–æ—Ç–∞")
            return
    except Exception as e:
        bot.reply_to(message, "‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–æ–≤–µ—Ä–∏—Ç—å –ø—Ä–∞–≤–∞ –∞–¥–º–∏–Ω–∏—Å—Ç—Ä–∞—Ç–æ—Ä–∞")
        return

    try:
        # –ò–∑–≤–ª–µ–∫–∞–µ–º —É—Ä–æ–≤–µ–Ω—å –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏ –∏–∑ —Ç–µ–∫—Å—Ç–∞ –∫–æ–º–∞–Ω–¥—ã
        activity_text = message.text[10:].strip()  # –£–±–∏—Ä–∞–µ–º "/activity "

        if not activity_text:
            current_level = activity_settings.get(str(message.chat.id), 5)
            bot.reply_to(message,
                f"üìä –¢–µ–∫—É—â–∏–π —É—Ä–æ–≤–µ–Ω—å –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏: {current_level}/10\n\n"
                "0 = –æ—Ç–≤–µ—á–∞—é —Ç–æ–ª—å–∫–æ –ø—Ä–∏ –æ—Ç–≤–µ—Ç–µ –Ω–∞ –º–æ–∏ —Å–æ–æ–±—â–µ–Ω–∏—è\n"
                "5 = —Å—Ä–µ–¥–Ω—è—è –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç—å (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é)\n"
                "10 = –æ—Ç–≤–µ—á–∞—é –Ω–∞ –≤—Å–µ —Å–æ–æ–±—â–µ–Ω–∏—è\n\n"
                "–ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ: /activity <0-10>"
            )
            return

        try:
            activity_level = int(activity_text)
            if activity_level < 0 or activity_level > 10:
                bot.reply_to(message, "‚ùå –£—Ä–æ–≤–µ–Ω—å –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏ –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –æ—Ç 0 –¥–æ 10")
                return
        except ValueError:
            bot.reply_to(message, "‚ùå –£—Ä–æ–≤–µ–Ω—å –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏ –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å —á–∏—Å–ª–æ–º –æ—Ç 0 –¥–æ 10")
            return

        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –Ω–∞—Å—Ç—Ä–æ–π–∫—É –≤ —Å–ª–æ–≤–∞—Ä—å –∏ –±–∞–∑—É
        activity_settings[str(message.chat.id)] = activity_level
        db.set_group_setting(message.chat.id, 'activity_level', activity_level)

        # –û–ø–∏—Å—ã–≤–∞–µ–º –ø–æ–≤–µ–¥–µ–Ω–∏–µ –¥–ª—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
        behavior_desc = {
            0: "–æ—Ç–≤–µ—á–∞—é —Ç–æ–ª—å–∫–æ –ø—Ä–∏ –æ—Ç–≤–µ—Ç–µ –Ω–∞ –º–æ–∏ —Å–æ–æ–±—â–µ–Ω–∏—è",
            1: "–æ—á–µ–Ω—å –Ω–∏–∑–∫–∞—è –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç—å (5%)",
            2: "–Ω–∏–∑–∫–∞—è –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç—å (10%)",
            3: "–ø–æ–Ω–∏–∂–µ–Ω–Ω–∞—è –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç—å (20%)",
            4: "—É–º–µ—Ä–µ–Ω–Ω–∞—è –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç—å (35%)",
            5: "—Å—Ä–µ–¥–Ω—è—è –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç—å (50%)",
            6: "–ø–æ–≤—ã—à–µ–Ω–Ω–∞—è –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç—å (65%)",
            7: "–≤—ã—Å–æ–∫–∞—è –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç—å (80%)",
            8: "–æ—á–µ–Ω—å –≤—ã—Å–æ–∫–∞—è –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç—å (90%)",
            9: "–º–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç—å (95%)",
            10: "–æ—Ç–≤–µ—á–∞—é –Ω–∞ –≤—Å–µ —Å–æ–æ–±—â–µ–Ω–∏—è (100%)"
        }

        bot.reply_to(message,
            f"‚úÖ –£—Ä–æ–≤–µ–Ω—å –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω: {activity_level}/10\n"
            f"üìù –ü–æ–≤–µ–¥–µ–Ω–∏–µ: {behavior_desc[activity_level]}"
        )

        logging.info(f"–ê–∫—Ç–∏–≤–Ω–æ—Å—Ç—å –≤ —á–∞—Ç–µ {message.chat.id} —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∞ –Ω–∞ {activity_level}")

    except Exception as e:
        error_msg = f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —É—Å—Ç–∞–Ω–æ–≤–∫–µ –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏: {str(e)}"
        print(error_msg)
        logging.error(error_msg)
        bot.reply_to(message, "‚ùå –ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ —É—Å—Ç–∞–Ω–æ–≤–∫–µ –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏")

@bot.message_handler(commands=['finetune'])
def start_finetune(message):
    global is_finetuning
    with train_data_lock:
        if is_finetuning:
            bot.reply_to(message, "–î–æ–æ–±—É—á–µ–Ω–∏–µ —É–∂–µ –∑–∞–ø—É—â–µ–Ω–æ, –ø–æ–¥–æ–∂–¥–∏—Ç–µ.")
            return
        data = db.load_train_data()
        if not data:
            bot.reply_to(message, "–ù–µ—Ç –Ω–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –¥–æ–æ–±—É—á–µ–Ω–∏—è.")
            return
        bot.reply_to(message, "–ù–∞—á–∏–Ω–∞—é –¥–æ–æ–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏ –Ω–∞ –Ω–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö...")
        is_finetuning = True

    try:
        texts = [pair[0] for pair in data] + [pair[1] for pair in data]
        sentences = []
        for t in texts:
            sentences.extend(split_text_to_sentences(t))
        sentences = sentences[:50]

        fine_tune(model, optimizer, bpe, sentences, epochs=10)

        with train_data_lock:
            db.clear_train_data()
        bot.reply_to(message, "–î–æ–æ–±—É—á–µ–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ –∏ –¥–∞–Ω–Ω—ã–µ –æ—á–∏—â–µ–Ω—ã.")
    except Exception as e:
        bot.reply_to(message, f"–û—à–∏–±–∫–∞ –≤–æ –≤—Ä–µ–º—è –¥–æ–æ–±—É—á–µ–Ω–∏—è: {e}")
        logging.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ manual fine-tuning: {e}")
    finally:
        is_finetuning = False

@bot.message_handler(commands=['train'])
def start_train_dialog(message):
    chat_id = message.chat.id
    user_training_buffers[chat_id] = []
    bot.reply_to(message, "–û—Ç–ø—Ä–∞–≤—å—Ç–µ —Ç–µ–∫—Å—Ç –¥–ª—è –æ–±—É—á–µ–Ω–∏—è. –ö–æ–≥–¥–∞ –∑–∞–∫–æ–Ω—á–∏—Ç–µ ‚Äî –Ω–∞–ø–∏—à–∏—Ç–µ /done.")

@bot.message_handler(commands=['done'])
def finish_train_dialog(message):
    chat_id = message.chat.id
    if chat_id not in user_training_buffers or not user_training_buffers[chat_id]:
        bot.reply_to(message, "–í—ã –Ω–µ –Ω–∞—á–∞–ª–∏ –≤–≤–æ–¥ —Ç–µ–∫—Å—Ç–∞ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è. –ù–∞–ø–∏—à–∏—Ç–µ /train —á—Ç–æ–±—ã –Ω–∞—á–∞—Ç—å.")
        return

    text = '\n'.join(user_training_buffers[chat_id])
    del user_training_buffers[chat_id]

    bot.reply_to(message, "–ù–∞—á–∏–Ω–∞—é –¥–æ–æ–±—É—á–µ–Ω–∏–µ –Ω–∞ –≤–∞—à–µ–º —Ç–µ–∫—Å—Ç–µ...")

    sentences = split_text_to_sentences(text)
    sentences = sentences[:500]

    def train_thread():
        global is_finetuning
        is_finetuning = True
        try:
            fine_tune(model, optimizer, bpe, sentences, epochs=10)
            bot.send_message(chat_id, "–î–æ–æ–±—É—á–µ–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ.")
        except Exception as e:
            bot.send_message(chat_id, f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –¥–æ–æ–±—É—á–µ–Ω–∏–∏: {e}")
        finally:
            is_finetuning = False

    threading.Thread(target=train_thread, daemon=True).start()

@bot.message_handler(func=lambda m: m.chat.id in user_training_buffers)
def collect_training_text(message):
    user_training_buffers[message.chat.id].append(message.text)

@bot.message_handler(commands=['image'])
def generate_image(message):
    try:
        prompt = message.text[7:].strip()
        print(f"[DEBUG] –ü–æ–ª—É—á–µ–Ω –∑–∞–ø—Ä–æ—Å –Ω–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ: '{prompt}'")
        if not prompt:
            bot.reply_to(message, "–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, —É–∫–∞–∂–∏—Ç–µ –æ–ø–∏—Å–∞–Ω–∏–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –ø–æ—Å–ª–µ –∫–æ–º–∞–Ω–¥—ã /image")
            return

        bot.reply_to(message, f"üé® –ì–µ–Ω–µ—Ä–∏—Ä—É—é –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –¥–ª—è: '{prompt}'...")

        generated_image_path = generate_image_from_text(prompt, bpe, max_images=5)
        print(f"[DEBUG] generate_image_from_text –≤–µ—Ä–Ω—É–ª–∞: {generated_image_path}")

        if generated_image_path and os.path.exists(generated_image_path):
            print(f"[DEBUG] –§–∞–π–ª –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è —Å—É—â–µ—Å—Ç–≤—É–µ—Ç: {generated_image_path}")
            with open(generated_image_path, 'rb') as photo:
                caption = f"üñºÔ∏è –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ: '{prompt[:30]}{'...' if len(prompt) > 30 else ''}'\n\nüí¨ –û—Ü–µ–Ω–∏—Ç–µ –∫–æ–º–∞–Ω–¥–æ–π /rate [1-5]"
                bot.send_photo(message.chat.id, photo, caption=caption)

            user_last_outputs[message.chat.id] = {
                'type': 'image',
                'query': prompt,
                'response': generated_image_path
            }

            db.insert_into('image_generations', prompt=prompt, image_path=generated_image_path, timestamp=str(time.time()))

            return

        else:
            print("[DEBUG] –§–∞–π–ª –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –Ω–µ –Ω–∞–π–¥–µ–Ω –∏–ª–∏ –ø—É—Ç—å –ø—É—Å—Ç")
            bot.reply_to(message, "‚ùå –ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è.")

    except Exception as e:
        logging.error(f"–û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è: {e}")
        traceback.print_exc()
        bot.reply_to(message, "‚ùå –ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è.")

@bot.message_handler(commands=['brain'])
def analyze_brain(message):
    try:
        # –ò–∑–≤–ª–µ–∫–∞–µ–º —Ç–µ–∫—Å—Ç –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
        text_to_analyze = message.text[7:].strip()
        
        if not text_to_analyze:
            bot.reply_to(message, "–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, —É–∫–∞–∂–∏—Ç–µ —Ç–µ–∫—Å—Ç –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –ø–æ—Å–ª–µ –∫–æ–º–∞–Ω–¥—ã /brain")
            return
        
        bot.reply_to(message, f"üß† –ê–Ω–∞–ª–∏–∑–∏—Ä—É—é —Ç–µ–∫—Å—Ç: '{text_to_analyze[:50]}{'...' if len(text_to_analyze) > 50 else ''}'")
        
        # –°–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏–π –∞–Ω–∞–ª–∏–∑
        from qsusli_model import analyze_semantic_meaning, get_context_keywords
        
        semantic_data = analyze_semantic_meaning(text_to_analyze)
        keywords = get_context_keywords(text_to_analyze)
        
        if semantic_data:
            result = f"üìä **–°–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏–π –∞–Ω–∞–ª–∏–∑:**\n"
            result += f"üéØ –û—Å–Ω–æ–≤–Ω–∞—è –∫–∞—Ç–µ–≥–æ—Ä–∏—è: {semantic_data['primary_category']}\n"
            result += f"üìù –í—Å–µ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏: {', '.join(semantic_data['all_categories'])}\n"
            result += f"üéöÔ∏è –£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å: {semantic_data['confidence']:.1%}\n"
            result += f"üìè –î–ª–∏–Ω–∞: {semantic_data['text_length']} —Å–ª–æ–≤\n"
            result += f"üß© –°–ª–æ–∂–Ω–æ—Å—Ç—å: {semantic_data['complexity']}\n"
            
            if keywords:
                result += f"üîë –ö–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞: {', '.join(keywords[:5])}\n"
            
            # –î–æ–±–∞–≤–ª—è–µ–º —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏
            if semantic_data['primary_category'] == '–≤–æ–ø—Ä–æ—Å':
                result += "\nüí° **–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è:** –≠—Ç–æ –≤–æ–ø—Ä–æ—Å - –º–æ–∂–Ω–æ –∏—Å–∫–∞—Ç—å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –≤ Wikipedia"
            elif semantic_data['primary_category'] == '—ç–º–æ—Ü–∏—è':
                result += "\nüí° **–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è:** –≠–º–æ—Ü–∏–æ–Ω–∞–ª—å–Ω—ã–π –∫–æ–Ω—Ç–µ–Ω—Ç - –ø–æ–¥—Ö–æ–¥–∏—Ç –¥–ª—è —Ç–≤–æ—Ä—á–µ—Å–∫–æ–≥–æ –æ—Ç–≤–µ—Ç–∞"
            elif semantic_data['primary_category'] == '–¥–µ–π—Å—Ç–≤–∏–µ':
                result += "\nüí° **–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è:** –û–ø–∏—Å–∞–Ω–∏–µ –¥–µ–π—Å—Ç–≤–∏—è - –º–æ–∂–Ω–æ –≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –ø–æ—à–∞–≥–æ–≤—ã–µ –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏"
            
            bot.reply_to(message, result)
        else:
            bot.reply_to(message, "‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–æ–≤–µ—Å—Ç–∏ —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏–π –∞–Ω–∞–ª–∏–∑")
            
        logging.info(f"–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å {message.from_user.id} –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–ª brain4 –∞–Ω–∞–ª–∏–∑ –¥–ª—è: '{text_to_analyze}'")
        
    except Exception as e:
        error_msg = f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∞–Ω–∞–ª–∏–∑–µ –º–æ–∑–≥–∞: {str(e)}"
        print(error_msg)
        logging.error(error_msg)
        bot.reply_to(message, "‚ùå –ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ –∞–Ω–∞–ª–∏–∑–µ")


@bot.message_handler(commands=['rate'])
def rate_response(message):
    try:
        rating_text = message.text[6:].strip()
        if not rating_text:
            bot.reply_to(message, "–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, —É–∫–∞–∂–∏—Ç–µ –æ—Ü–µ–Ω–∫—É –æ—Ç 1 –¥–æ 5 –ø–æ—Å–ª–µ –∫–æ–º–∞–Ω–¥—ã /rate")
            return

        try:
            rating = int(rating_text)
            if rating < 1 or rating > 5:
                bot.reply_to(message, "–û—Ü–µ–Ω–∫–∞ –¥–æ–ª–∂–Ω–∞ –±—ã—Ç—å –æ—Ç 1 –¥–æ 5")
                return
        except ValueError:
            bot.reply_to(message, "–û—Ü–µ–Ω–∫–∞ –¥–æ–ª–∂–Ω–∞ –±—ã—Ç—å —á–∏—Å–ª–æ–º –æ—Ç 1 –¥–æ 5")
            return

        last_output = user_last_outputs.get(message.chat.id)
        print(f"–û—Ü–µ–Ω–∏–≤–∞–µ–º—ã–π –æ–±—ä–µ–∫—Ç: {last_output}")
        if not last_output:
            bot.reply_to(message, "–°–Ω–∞—á–∞–ª–∞ –ø–æ–ª—É—á–∏—Ç–µ –æ—Ç–≤–µ—Ç –∏–ª–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –æ—Ç –±–æ—Ç–∞, —á—Ç–æ–±—ã –µ–≥–æ –æ—Ü–µ–Ω–∏—Ç—å.")
            return

        user_id = message.from_user.id
        query = last_output.get('query', '')
        response = last_output.get('response', '')

        if last_output.get('type') == 'image':
            from qsusli_model import evaluate_image_quality, reinforcement_learning_update, improve_unknown_word_generation

            normalized_rating = (rating - 1) / 4.0

            quality = evaluate_image_quality(response, user_rating=normalized_rating)

            category = improve_unknown_word_generation(query) or 'default'
            generation_params = {
                'colors': [],  # –ú–æ–∂–Ω–æ –∏–∑–≤–ª–µ—á—å –∏–∑ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
                'shapes': '',
                'query': query
            }

            reinforcement_learning_update(category, normalized_rating, generation_params)
            print(f"üß† RLHF: –û–±–Ω–æ–≤–ª–µ–Ω–∞ –ø–æ–ª–∏—Ç–∏–∫–∞ –¥–ª—è '{category}' —Å –æ—Ü–µ–Ω–∫–æ–π {normalized_rating:.3f}")

            db.insert_into(
                'image_ratings',
                user_id=user_id,
                query=query,
                image_path=response,
                rating=rating,
                normalized_rating=normalized_rating,
                auto_score=quality.get('auto_score', 0.5),
                timestamp=str(time.time())
            )

            emoji_map = {1: "üòû", 2: "üòê", 3: "üôÇ", 4: "üòä", 5: "ü§©"}
            bot.reply_to(message, f"–°–ø–∞—Å–∏–±–æ –∑–∞ –æ—Ü–µ–Ω–∫—É! {emoji_map[rating]} –í–∞—à–∞ –æ—Ü–µ–Ω–∫–∞: {rating}/5\n"
                                  f"–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∞—è –æ—Ü–µ–Ω–∫–∞: {quality['auto_score']:.2f}\n"
                                  f"–≠—Ç–∞ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –ø–æ–º–æ–∂–µ—Ç —É–ª—É—á—à–∏—Ç—å –∫–∞—á–µ—Å—Ç–≤–æ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π!")

        elif last_output.get('type') == 'text':
            db.insert_into(
                'text_ratings',
                user_id=user_id,
                query=query,
                response=response,
                rating=rating,
                timestamp=str(time.time())
            )
            bot.reply_to(message, f"–°–ø–∞—Å–∏–±–æ –∑–∞ –æ—Ü–µ–Ω–∫—É —Ç–µ–∫—Å—Ç–∞ {rating}! –≠—Ç–æ –ø–æ–º–æ–∂–µ—Ç —É–ª—É—á—à–∏—Ç—å –º–µ–Ω—è.")
        else:
            bot.reply_to(message, "–ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π —Ç–∏–ø –ø–æ—Å–ª–µ–¥–Ω–µ–≥–æ –æ—Ç–≤–µ—Ç–∞ –¥–ª—è –æ—Ü–µ–Ω–∫–∏.")

    except Exception as e:
        logging.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ /rate: {e}")
        traceback.print_exc()
        bot.reply_to(message, "‚ùå –ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–∏ –æ—Ü–µ–Ω–∫–∏.")


@bot.message_handler(commands=['correct'])
def handle_correct(message):
    chat_id = message.chat.id
    user_id = message.from_user.id
    corrected_text = message.text[len('/correct'):].strip()

    last_output = user_last_outputs.get(chat_id)
    if not last_output or last_output.get('type') != 'text':
        bot.reply_to(message, "–ù–µ—Ç –ø–æ—Å–ª–µ–¥–Ω–µ–≥–æ —Ç–µ–∫—Å—Ç–æ–≤–æ–≥–æ –æ—Ç–≤–µ—Ç–∞ –¥–ª—è –∫–æ—Ä—Ä–µ–∫—Ç–∏—Ä–æ–≤–∫–∏.")
        return

    original_query = last_output.get('query')
    original_response = last_output.get('response')

    if not corrected_text:
        bot.reply_to(message, "–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, —É–∫–∞–∂–∏—Ç–µ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–Ω—ã–π –≤–∞—Ä–∏–∞–Ω—Ç –ø–æ—Å–ª–µ –∫–æ–º–∞–Ω–¥—ã.")
        return

    db.save_correction(user_id=user_id, query=original_query, original_response=original_response, corrected_response=corrected_text, timestamp=time.time())

    threading.Thread(target=process_rlhf_correction, args=(original_query, original_response, corrected_text), daemon=True).start()

    bot.reply_to(message, "–°–ø–∞—Å–∏–±–æ! –í–∞—à –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–Ω—ã–π –æ—Ç–≤–µ—Ç —É—á—Ç—ë–Ω –¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è –º–æ–¥–µ–ª–∏.")


@bot.message_handler(func=lambda m: True)
def handle_message(message):
    global is_finetuning

    if is_finetuning:
        bot.reply_to(message, "–°–µ–π—á–∞—Å –∏–¥–µ—Ç –¥–æ–æ–±—É—á–µ–Ω–∏–µ, –ø–æ–ø—Ä–æ–±—É–π—Ç–µ –ø–æ–∑–∂–µ.")
        return

    user_text = message.text
    if not user_text or not user_text.strip():
        bot.reply_to(message, "–ü—É—Å—Ç–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ, –ø–æ–ø—Ä–æ–±—É–π—Ç–µ –µ—â—ë —Ä–∞–∑.")
        return

    user_text_lower = user_text.lower()

    # –ü–æ–ª—É—á–∞–µ–º –∏–ª–∏ —Å–æ–∑–¥–∞—ë–º —Ä–∞–±–æ—á–µ–µ –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–æ –¥–ª—è —Ç–µ–∫—É—â–µ–≥–æ —á–∞—Ç–∞
    workspace = workspaces.get(message.chat.id)
    if not workspace:
        from qsusli_model import GlobalWorkspace
        workspace = GlobalWorkspace()
        workspaces[message.chat.id] = workspace

    # –û—á–∏—Å—Ç–∫–∞ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –ø–æ –∫–æ–º–∞–Ω–¥–µ
    if user_text_lower.strip() in ['/clearcontext', '/resetcontext']:
        workspace.dialog_history.clear()
        workspace.context_keywords.clear()
        workspace.semantic_info = None
        workspace.current_prompt = None
        bot.reply_to(message, "–ö–æ–Ω—Ç–µ–∫—Å—Ç –æ—á–∏—â–µ–Ω.")
        return

    # –û–±–Ω–æ–≤–ª—è–µ–º —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏–π –∫–æ–Ω—Ç–µ–∫—Å—Ç –∏ –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞
    try:
        from qsusli_model import analyze_semantic_meaning, get_context_keywords, improve_unknown_word_generation, get_rlhf_params_for_category
        semantic_context = analyze_semantic_meaning(user_text_lower)
        context_keywords = get_context_keywords(user_text_lower)
        workspace.update_semantic(semantic_context)
        workspace.update_keywords(context_keywords)
        workspace.set_current_prompt(user_text_lower)

        category = improve_unknown_word_generation(user_text_lower) or 'default'
        rlhf_params = get_rlhf_params_for_category(category)
    except Exception as e:
        logging.error(f"–û—à–∏–±–∫–∞ —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞ –∏–ª–∏ RLHF: {e}")
        category = 'default'
        rlhf_params = {}

    # –õ–æ–≥–∏–∫–∞ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è, –Ω—É–∂–Ω–æ –ª–∏ –æ—Ç–≤–µ—á–∞—Ç—å, —Å –ø–æ–¥—Ä–æ–±–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–æ–π –≥—Ä—É–ø–ø
    should_respond = True
    if message.chat.type in ['group', 'supergroup']:
        activity_level = activity_settings.get(str(message.chat.id), 2)  # –ó–Ω–∞—á–µ–Ω–∏–µ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é

        if activity_level == 0:
            # –û—Ç–≤–µ—á–∞–µ–º —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ —Å–æ–æ–±—â–µ–Ω–∏–µ ‚Äî –æ—Ç–≤–µ—Ç –Ω–∞ —Å–æ–æ–±—â–µ–Ω–∏–µ –±–æ—Ç–∞
            should_respond = False
            if message.reply_to_message and message.reply_to_message.from_user.is_bot:
                should_respond = True
                logging.info(f"–ì—Ä—É–ø–ø–∞ {message.chat.id}: –æ—Ç–≤–µ—Ç –Ω–∞ —Å–æ–æ–±—â–µ–Ω–∏–µ –±–æ—Ç–∞ (–∞–∫—Ç–∏–≤–Ω–æ—Å—Ç—å 0)")

        else:
            base_chance = max(0.05, activity_level / 20.0)  # –ù–µ–º–Ω–æ–≥–æ –ø–æ–Ω–∏–∂–µ–Ω–Ω—ã–π –±–∞–∑–æ–≤—ã–π —à–∞–Ω—Å
            response_chance = base_chance

            if len(user_text_lower.strip()) <= 2:
                should_respond = False
                logging.info(f"–ì—Ä—É–ø–ø–∞ {message.chat.id}: –ø—Ä–æ–ø—É—Å–∫ –∫–æ—Ä–æ—Ç–∫–æ–≥–æ —Å–æ–æ–±—â–µ–Ω–∏—è '{user_text_lower}'")
            else:
                if any(word in user_text_lower for word in ['qsusli', '–±–æ—Ç', 'bot', '@']):
                    response_chance = min(0.8, base_chance + 0.4)
                elif message.reply_to_message and message.reply_to_message.from_user.is_bot:
                    response_chance = min(0.9, base_chance + 0.6)
                elif any(word in user_text_lower for word in ['—á—Ç–æ', '–∫–∞–∫', '–≥–¥–µ', '–∫–æ–≥–¥–∞', '–ø–æ—á–µ–º—É', '–∑–∞—á–µ–º', '?']):
                    response_chance = min(0.6, base_chance + 0.2)
                elif any(word in user_text_lower for word in ['–ø—Ä–∏–≤–µ—Ç', 'hi', 'hello', '–ø–æ–º–æ—â—å', 'help']):
                    response_chance = min(0.7, base_chance + 0.3)

                should_respond = random.random() < response_chance

                if should_respond:
                    logging.info(f"–ì—Ä—É–ø–ø–∞ {message.chat.id}: –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç—å {activity_level}/10, —à–∞–Ω—Å {response_chance:.2f}, –æ—Ç–≤–µ—á–∞–µ–º")

    generated_text = "–ë–µ–∑ –æ—Ç–≤–µ—Ç–∞"
    if should_respond:
        try:
            full_tokens = bpe.encode(user_text_lower)
            start_tokens = tokens_to_indices(full_tokens[:3], bpe.vocab)
            if not start_tokens or all(token == bpe.vocab.get('<unk>', 0) for token in start_tokens):
                for word in user_text_lower.split():
                    word_tokens = tokens_to_indices(bpe.encode(word), bpe.vocab)
                    if word_tokens and not all(token == bpe.vocab.get('<unk>', 0) for token in word_tokens):
                        start_tokens = word_tokens[:2]
                        break
                if not start_tokens or all(token == bpe.vocab.get('<unk>', 0) for token in start_tokens):
                    start_tokens = [list(bpe.vocab.values())[torch.randint(0, len(bpe.vocab), (1,)).item()]]

            generation_params = {
                'temperature': rlhf_params.get('temperature', 0.7),
                'max_len': rlhf_params.get('max_len', 25),
                'top_k': rlhf_params.get('top_k', 50),
                'top_p': rlhf_params.get('top_p', 0.9)
            }

            generation_params = workspace.meta_learning_update(generation_params)

            generated_tokens = generate_text(
                model,
                start_tokens,
                max_len=generation_params['max_len'],
                inv_vocab=inv_vocab,
                temperature=generation_params['temperature'],
                top_k=generation_params['top_k'],
                top_p=generation_params['top_p']
            )

            text_parts = []
            for token in generated_tokens:
                if token == '<space>':
                    text_parts.append(' ')
                elif token.endswith('</w>'):
                    text_parts.append(token.replace('</w>', ''))
                    text_parts.append(' ')
                elif token != '<unk>':
                    text_parts.append(token)
            generated_text = ''.join(text_parts).strip()

            if len(generated_text) < 3 or generated_text.count(' ') < 1:
                generated_tokens = generate_text(
                    model,
                    start_tokens,
                    max_len=15,
                    inv_vocab=inv_vocab,
                    temperature=0.5,
                    top_k=50,
                    top_p=0.9
                )
                text_parts = []
                for token in generated_tokens:
                    if token == '<space>':
                        text_parts.append(' ')
                    elif token.endswith('</w>'):
                        text_parts.append(token.replace('</w>', ''))
                        text_parts.append(' ')
                    elif token != '<unk>':
                        text_parts.append(token)
                generated_text = ''.join(text_parts).strip()

            if not generated_text or len(generated_text) < 2:
                generated_text = "–ò–Ω—Ç–µ—Ä–µ—Å–Ω–æ..."

            success = safe_send_message(message, generated_text)
            if not success:
                logging.warning(f"Failed to send message to chat {message.chat.id}: '{generated_text[:50]}...'")
                generated_text = "–°–æ–æ–±—â–µ–Ω–∏–µ –Ω–µ –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω–æ –∏–∑-–∑–∞ –ª–∏–º–∏—Ç–æ–≤"

            workspace.add_dialog_pair(user_text_lower, generated_text)

            user_last_outputs[message.chat.id] = {
                'type': 'text',
                'query': user_text_lower,
                'response': generated_text
            }

            with train_data_lock:
                db.insert_into('train_data', input_text=user_text_lower, output_text=generated_text, timestamp=str(time.time()))

        except Exception as e:
            logging.error(f"–û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –æ—Ç–≤–µ—Ç–∞: {e}")
            safe_send_message(message, "–ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –æ—Ç–≤–µ—Ç–∞.")

    # –î–æ–±–∞–≤–ª–µ–Ω–∏–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π –∏–∑ Wikipedia –¥–ª—è –æ–±—É—á–µ–Ω–∏—è
    with train_data_lock:
        try:
            if should_respond and len(user_text_lower) > 5 and random.random() < 0.3:
                wiki_sentences = search_wikipedia(user_text_lower, sentences_limit=2)
                if wiki_sentences:
                    for sent in wiki_sentences:
                        db.insert_into('train_data', input_text=sent, output_text=sent, timestamp=str(time.time()))
                    logging.info(f"Wikipedia: –¥–æ–±–∞–≤–ª–µ–Ω–æ {len(wiki_sentences)} –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π")
        except Exception as e:
            logging.warning(f"Wikipedia search error: {e}")


if __name__ == '__main__':
    try:
        threading.Thread(target=auto_finetune_loop, daemon=True).start()
        logging.info("–ë–æ—Ç –∑–∞–ø—É—â–µ–Ω...")
        print("–ë–æ—Ç –∑–∞–ø—É—â–µ–Ω...")
        
        while True:
            try:
                bot.polling(none_stop=True, interval=1, timeout=60)
            except Exception as e:
                print(f"–û—à–∏–±–∫–∞ polling: {e}")
                logging.error(f"–û—à–∏–±–∫–∞ polling: {e}")
                time.sleep(5)  # –ü–∞—É–∑–∞ –ø–µ—Ä–µ–¥ –ø–µ—Ä–µ–∑–∞–ø—É—Å–∫–æ–º
                print("–ü–µ—Ä–µ–∑–∞–ø—É—Å–∫–∞—é polling...")
                
    except KeyboardInterrupt:
        print("–ë–æ—Ç –æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º")
        logging.info("–ë–æ—Ç –æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º")
    except Exception as e:
        print(f"–ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ –±–æ—Ç–∞: {e}")
        logging.error(f"–ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ –±–æ—Ç–∞: {e}")
        traceback.print_exc()
